{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xrcgbhQzykz7",
        "7FP9uw7rRDy_",
        "c4wBMHkxU883",
        "tLuGJN9lWXVq",
        "s6U_96CCRwKV"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "cp37jZZssKxy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "xggTqjEcsF-T"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import KNeighborsRegressor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_state = 1000\n",
        "df = pd.read_csv(\"crypto.csv\")\n",
        "data_size = 100000 #Change this to adjust the dataset size partition"
      ],
      "metadata": {
        "id": "p1kvVk9huCli"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "ni3DtdjFuKFA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Say that selected both datasets because in small datasets we got super good results immediately an"
      ],
      "metadata": {
        "id": "QkRqsc7p583L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df.isna().sum()\n",
        "df.dropna(inplace = True)"
      ],
      "metadata": {
        "id": "58FCkfs1uMQ8"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.head() # We can see data is already sorted based on date so we can drop the date column."
      ],
      "metadata": {
        "id": "U7WKl1J1xPqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.info()"
      ],
      "metadata": {
        "id": "wRWKPZm7rFeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['time', 'id'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "swlsh99vxgGJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plotting the correlation map**"
      ],
      "metadata": {
        "id": "z4I3YYTQSLzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16, 8))\n",
        "sns.set(style=\"whitegrid\")\n",
        "corr = df.corr()\n",
        "sns.heatmap(corr,annot=True, cmap=\"YlGnBu\")\n",
        "# Shows almost no correlation between amount and closing price"
      ],
      "metadata": {
        "id": "oXnsE9WXSR77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scaling the data and creating datasets**"
      ],
      "metadata": {
        "id": "1tnRjJfaxkJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scale = StandardScaler()\n",
        "df_sc = scale.fit_transform(df)\n",
        "df_sc = pd.DataFrame(df_sc, columns=df.columns)"
      ],
      "metadata": {
        "id": "rLnWV47V1kFe"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df_sc['close'] # The aim is to predict the closing price of Netflix' stock.\n",
        "X = df_sc.drop('close', axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X[:data_size], y[:data_size], test_size=0.4, random_state=random_state) # Splitting as 60% train test, 40% test set."
      ],
      "metadata": {
        "id": "ebiza2nKyXXv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression with SVR"
      ],
      "metadata": {
        "id": "xrcgbhQzykz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SVM_regression = SVR(C=1, kernel='rbf')"
      ],
      "metadata": {
        "id": "ArCRZn-Jym01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SVM_regression.fit(X_train, y_train) # training the model."
      ],
      "metadata": {
        "id": "42Fr57iQpNZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = SVM_regression.predict(X_test) # Predicting values"
      ],
      "metadata": {
        "id": "9lZy6xrIysTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = pd.DataFrame({'y_test':y_test, 'y_pred':y_pred})"
      ],
      "metadata": {
        "id": "X7nJXv5jysqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluating the model**"
      ],
      "metadata": {
        "id": "lLUHsP0Syx3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MSE_test = round(np.mean(np.square(y_test- y_pred)),2)\n",
        "RMSE_test = round(np.sqrt(MSE_test),2)\n",
        "print(RMSE_test, SVM_regression.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "kuPL8WHDy0lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.head()"
      ],
      "metadata": {
        "id": "m3Rbbhl-y61f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grid Search and Optimal Model"
      ],
      "metadata": {
        "id": "7FP9uw7rRDy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'C': [1,10,100], 'gamma': [10, 1,0.1,0.01], 'kernel': ['rbf', 'poly', 'sigmoid', 'linear'], 'degree' : [3,5,9]}"
      ],
      "metadata": {
        "id": "BUIGKnBoRHTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid = GridSearchCV(estimator=SVR(),param_grid= param_grid, refit = True, verbose=3, cv=2)"
      ],
      "metadata": {
        "id": "nLor42jyRQfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "xINBOhxZRRCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TPV9SGYRSKF",
        "outputId": "cafe01c2-a185-48a4-eb92-50226149e76c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 1, 'degree': 3, 'gamma': 10, 'kernel': 'rbf'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_best = grid.predict(X_test)"
      ],
      "metadata": {
        "id": "KBKo8RakRUjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE_test = round(np.mean(np.square(y_test- y_pred_best)),2)\n",
        "RMSE_test = round(np.sqrt(MSE_test),2)\n",
        "print(RMSE_test, grid.best_estimator_.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "ke4S-hlvReL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimal Model"
      ],
      "metadata": {
        "id": "8l2RnmbQRZHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimal = SVR(C=1, gamma = 0.1, kernel = 'rbf') # Change the gamma to 0.1 and see what happens. Hint: Magic!"
      ],
      "metadata": {
        "id": "NOG_mz83Rlvx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimal.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "m1ESIqN2RpE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_optimal = optimal.predict(X_test)"
      ],
      "metadata": {
        "id": "jc652pdxRqNr"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE_opt = round(np.mean(np.square(y_test - y_optimal)),4)\n",
        "RMSE_opt = round(np.sqrt(MSE_opt),4)\n",
        "print(RMSE_opt, optimal.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "dBy7LHj1RsQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving the trained model**"
      ],
      "metadata": {
        "id": "xlM2jZVBiBn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(optimal, 'CryptoSVR.joblib') # To load the trained model simply use joblib.load('CryptoSVR.joblib')"
      ],
      "metadata": {
        "id": "oruGrXn5iAwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the model in an increasing amount of data**"
      ],
      "metadata": {
        "id": "G9BHxZcLCxkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "partition = (1000, 10000, 100000, 250000, 500000)"
      ],
      "metadata": {
        "id": "p1YoULLRzzQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " for i in partition:\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X[:i], y[:i], test_size=0.4, random_state=random_state)\n",
        "  optimal.fit(X_train, y_train)\n",
        "  y_optimal = optimal.predict(X_test)\n",
        "  MSE_opt = round(np.mean(np.square(y_test - y_optimal)),4) #asafg\n",
        "  print(\"Number of samples: \", i, \"RMSE: \", MSE_opt, \"R2 score\" , optimal.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "b2UAkv5Oz71s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting the learning curve"
      ],
      "metadata": {
        "id": "tLuGJN9lWXVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X[:data_size], y[:data_size], test_size=0.4, random_state=random_state) # Splitting as 60% train test, 40% test set.\n",
        "# Increasing the amount of samples to train"
      ],
      "metadata": {
        "id": "B3EOBgJbZJTb"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "def plot_learning_curve(estimator, X, y, ylim, cv, n_jobs, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    plt.figure()\n",
        "    plt.title(\"Learning Curve\")\n",
        "    if ylim is not None:\n",
        "        plt.ylim(*ylim)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    plt.grid()\n",
        "\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                     color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "\n",
        "    plt.legend(loc=\"best\")\n",
        "    return plt\n",
        "\n",
        "# Usage example:\n",
        "# Replace 'your_estimator', 'X_train', 'y_train' with your actual estimator and data\n",
        "# Make sure to set appropriate ylim based on your metric (e.g., R^2 score ranges from -∞ to 1)\n",
        "# You can also set other parameters like cv (cross-validation folds) and n_jobs (parallelization)\n",
        "negative_infinity =  float('-inf')\n",
        "plot_learning_curve(KNN, X_train, y_train, ylim=(0.8, 1), cv=2, n_jobs=-1)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aRTFbb7xWZSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare with KNN"
      ],
      "metadata": {
        "id": "s6U_96CCRwKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "KNN = KNeighborsRegressor()"
      ],
      "metadata": {
        "id": "24LzL3AjRyY7"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KNN.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "GzvlfbWER6SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_knn = KNN.predict(X_test)"
      ],
      "metadata": {
        "id": "yvOuNt0IR7Xb"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE_opt_knn = round(np.mean(np.square(y_test - y_knn)),4)\n",
        "print(MSE_opt_knn, KNN.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "WTDKEZNYkC23"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}